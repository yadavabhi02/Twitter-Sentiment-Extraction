{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"****Importing Libraries****\n","metadata":{}},{"cell_type":"code","source":"import re\nimport pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")\ntest=pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dropna(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp=train.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp.style.background_gradient(cmap=\"Blues\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure(go.Funnelarea(\n    text =temp.sentiment,\n    values = temp.text,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_jaccard=[]\n\nfor ind,row in train.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n\n    jaccard_score = jaccard(sentence1,sentence2)\n    results_jaccard.append([sentence1,sentence2,jaccard_score])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jaccard = pd.DataFrame(results_jaccard,columns=[\"text\",\"selected_text\",\"jaccard_score\"])\ntrain = train.merge(jaccard,how='outer')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Num_words_ST']=train['selected_text'].apply(lambda x:len(str(x).split()))\ntrain['Num_words_Text']=train['text'].apply(lambda x:len(str(x).split()))\ntrain['difference_in_words']=train['Num_words_Text']-train['Num_words_ST']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_data = [train['Num_words_ST'],train['Num_words_Text']]\n\ngroup_labels = ['Selected_Text', 'Text']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels,show_curve=False)\nfig.update_layout(title_text='Distribution of Number Of words')\nfig.update_layout(\n    autosize=False,\n    width=900,\n    height=700,\n    paper_bgcolor=\"LightSteelBlue\",\n)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**See the difference in number of words for each sentiment using kdeplot**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train['Num_words_ST'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\np1=sns.kdeplot(train['Num_words_Text'], shade=True, color=\"b\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In the above plot we can see the no of tweets with no of words greater than 25 are very less**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train[train['sentiment']=='positive']['difference_in_words'], shade=True, color=\"b\").set_title('Kernel Distribution of Difference in Number Of words')\np2=sns.kdeplot(train[train['sentiment']=='negative']['difference_in_words'], shade=True, color=\"r\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'],shade=True,color=\"b\").set_title('KDE of the jaccard scores across different sentiments')\nsns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'],shade=True,color=\"r\").set_title('KDE of the jaccard scores across different sentiments')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SO THE CONCLUSION FROM THE EXPLORATORY DATA ANALYSIS IS THAT THE POSITIVE AND NEGATIVE TWEETS ARE SEEING A BUMP AROUND JACCARD SCORE OF 1.\nSO WE SHOULD FOCUS ON FINDING THESE TWEETS HAVING JACCARD SCORE AROUND 1.**","metadata":{}},{"cell_type":"code","source":"k=train[train['Num_words_Text']<=2]\nk.groupby('sentiment').mean()['jaccard_score']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k[k['sentiment']=='positive']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**WE WILL FIRST CLEAN THE TWEETS**","metadata":{}},{"cell_type":"code","source":"import string","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_tweet(text):\n    text=str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text) #remove all the expression inside the square brackets\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)#remove the links\n    text = re.sub('<.*?>+', '', text)#remove the expressions inside the angular brackets like XML and HTML tags\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)#remove the punctuation marks\n    text = re.sub('\\n', '', text)#remove the endline characters \n    text = re.sub('\\w*\\d\\w*', '', text)#remove the words containing a digit atleast in between two words\n    return text\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['text']=train['text'].apply(lambda x:clean_tweet(x))\ntrain['selected_text']=train['selected_text'].apply(lambda x:clean_tweet(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['temp_list']=train['selected_text'].apply(lambda x:str(x).split())\ndef remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Purples')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['temp_list1']=train['text'].apply(lambda x:str(x).split())\ntrain['temp_list1'] = train['temp_list1'].apply(lambda x:remove_stopword(x)) #Removing Stopwords(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top = Counter([item for sublist in train['temp_list1'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Classifying the most common words sentiment wise:**","metadata":{}},{"cell_type":"code","source":"positive_sent=train[train['sentiment']=='positive']\nnegative_sent=train[train['sentiment']=='negative']\nneutral_sent=train[train['sentiment']=='neutral']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top = Counter([item for sublist in positive_sent['temp_list'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['Common_words','count']\ntemp_positive.style.background_gradient(cmap='Greens')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top = Counter([item for sublist in negative_sent['temp_list'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:]\ntemp_negative.columns = ['Common_words','count']\ntemp_negative.style.background_gradient(cmap='Greens')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top = Counter([item for sublist in neutral_sent['temp_list'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.iloc[1:,:]\ntemp_neutral.columns = ['Common_words','count']\ntemp_neutral.style.background_gradient(cmap='Greens')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_text=[word for word_list in train['temp_list1'] for word in word_list]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FUNCTION FOR UNIQUE WORDS**","metadata":{}},{"cell_type":"code","source":"def words_unique(sentiment,numwords,raw_words):\n    '''\n    Input:\n        segment - Segment category (ex. 'Neutral');\n        numwords - how many specific words do you want to see in the final result; \n        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n    Output: \n        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n\n    '''\n    allother = []\n    for item in train[train.sentiment != sentiment]['temp_list1']:#for those sentiments where the sentiment is not equal to the given one\n        for word in item:\n            allother .append(word)\n    allother  = list(set(allother ))  #set is used here because we want the list to contain non duplicate values\n    \n    specificnonly = [x for x in raw_text if x not in allother]\n    \n    mycounter = Counter()\n    \n    for item in train[train.sentiment == sentiment]['temp_list1']:\n        for word in item:\n            mycounter[word] += 1\n    keep = list(specificnonly)\n    \n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n    \n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n    \n    return Unique_words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FOR THE POSITIVE SENTIMENT ONES**","metadata":{}},{"cell_type":"code","source":"Unique_positive=words_unique('positive',25,raw_text)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The top 25 unique words in the Positive Tweets are: \")\nUnique_positive.style.background_gradient(cmap='Greens')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Treemap for unique positive words**","metadata":{}},{"cell_type":"code","source":"fig = px.treemap(Unique_positive, path=['words'], values='count',title='Tree for Unique Positive Words')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_positive['count'], labels=Unique_positive.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot for Unique Positive Words')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Unique_negative=words_unique('negative',25,raw_text)\nprint(\"The 25 unique negative words are:\")\nUnique_negative.style.background_gradient(cmap='Blues')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_negative['count'], labels=Unique_negative.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot for Unique negative Words')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Unique_Neutral= words_unique('neutral', 25, raw_text)\nprint(\"The top 10 unique words in Neutral Tweets are:\")\nUnique_Neutral.style.background_gradient(cmap='Oranges')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot for Unique Neutral Words')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MODELLING**","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nsubmission_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**WE ARE TAKING THE NUM WORDS TEXT GREATER THAN 3 DIRECTLY BECAUSE THEY CAN BE TAKEN DIRECTLY WITHOUT ANY PREPROCESSING**","metadata":{}},{"cell_type":"code","source":"train_df['Num_words_text'] = train_df['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set\ntrain_df = train_df[train_df['Num_words_text']>=3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**USING SPACY MODEL**","metadata":{}},{"cell_type":"code","source":"from spacy.training.example import Example","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#dropping null values rows\n\ntrain_df = train_df.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_model(output_dir, nlp, new_model_name):\n    output_dir = f'../working/{output_dir}'\n    \n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved a model to --\", output_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining train\n\ndef train(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    \n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe('ner', last = True)\n        \n    # otherwise, get it so we can have labels added\n    \n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        \n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n    for itr in tqdm( range(n_iter)): \n        \n        losses = {}\n        \n        for batch in spacy.util.minibatch(train_data, size = 2):\n            for text, annotations in batch:\n                # create Example\n                doc = nlp.make_doc(text)\n                example = Example.from_dict(doc, annotations)\n                # Updating the model\n                nlp.update([example], losses = losses, drop = 0.3)\n\n        print(\"Losses\", losses)\n        \n    save_model(output_dir, nlp, 'st_ner')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model_out_path(sentiment):\n    model_out_path = None\n    if sentiment == 'positive':\n        model_out_path = 'kaggle/input/tse-spacy-model/models/model_pos'\n    elif sentiment == 'negative':\n        model_out_path = 'kaggle/input/tse-spacy-model/models/model_neg'\n    else:\n        model_out_path = 'kaggle/input/tse-spacy-model/models/model_neu'\n    return model_out_path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating data in spacy data input format\n\ndef get_training_data(sentiment):\n    train_data = []\n    for index, row in train_df.iterrows():\n        #for each sentiment\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n            \n    return train_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#positive sentiment\nsentiment = 'positive'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n\n# training for 3 iterations\ntrain(train_data, model_path, n_iter = 3, model = None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#negative sentiment\nsentiment = 'negative'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n\n# training model for 3 iterations\ntrain(train_data, model_path, n_iter = 3, model = None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#neutral sentiment\nsentiment = 'neutral'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n\n# training model for 3 iterations\ntrain(train_data, model_path, n_iter = 3, model = None)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_models_path = 'kaggle/input/tse-spacy-model/models/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard(str1, str2): \n    doc1 = set(str1.lower().split()) \n    doc2 = set(str2.lower().split())\n    c = doc1.intersection(doc2)\n    return float(len(c)) / (len(doc1) + len(doc2) - len(c))\n\n\nif trained_models_path is not None:\n    print(\"Loading the models  from \", trained_models_path)\n    model_pos = spacy.load(trained_models_path + 'model_pos')\n    model_neg = spacy.load(trained_models_path + 'model_neg')\n    model_neu = spacy.load(trained_models_path + 'model_neu')\n        \n    jaccard_score = 0\n    for index, row in tqdm(train_df.iterrows(), total=train_df.shape[0]):\n        text = row.text\n        if row.sentiment == 'neutral':\n            jaccard_score += jaccard(predict_entities(text, model_neu), row.selected_text)\n        elif row.sentiment == 'positive':\n            jaccard_score += jaccard(predict_entities(text, model_pos), row.selected_text)\n        else:\n            jaccard_score += jaccard(predict_entities(text, model_neg), row.selected_text) \n        \n    print(f'The average Jaccard Score is : {jaccard_score / train_df.shape[0]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#paths\nBASE_PATH = '../input/tweet-sentiment-extraction/'\nMODELS_BASE_PATH = 'kaggle/input/tse-spacy-model/models/'\nMODELS_BASE_PATH2 = 'kaggle/input/tse-spacy-model/models/'\n\ntest_df = pd.read_csv( BASE_PATH + 'test.csv')\nsubmission_df = pd.read_csv( BASE_PATH + 'sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_texts = []\n\nif MODELS_BASE_PATH is not None:\n    \n    print(\"Loading Models  from \", MODELS_BASE_PATH)\n    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n    model_neg = spacy.load(MODELS_BASE_PATH2 + 'model_neg')\n    model_neu = spacy.load(MODELS_BASE_PATH + 'model_neu')\n        \n    for index, row in test_df.iterrows():\n        text = row.text\n        output_str = \"\"\n        if row.sentiment == 'neutral' or len(text.split()) < 4:\n            selected_texts.append(text)\n        elif row.sentiment == 'positive':\n            selected_texts.append(predict_entities(text, model_pos))\n        else:\n            selected_texts.append(predict_entities(text, model_neg))\n        \ntest_df['selected_text'] = selected_texts","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['selected_text']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df['selected_text'] = test_df['selected_text']\nsubmission_df.to_csv(\"submission.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"display(submission_df.head(15))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**BERT Modelling**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nimport transformers\nimport tokenizers\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    FOLDS=5\n    MAX_LEN=128\n    TRAIN_BATCH_SIZE=64\n    VALID_BATCH_SIZE=16\n    EPOCHS=5\n    BERT_PATH=\"/kaggle/input/bert-base-uncased\"\n    ROBERTA_PATH=\"/kaggle/input/roberta-base\"\n    TRAINING_FILE=\"../input/tweet-train-folds/train_folds.csv\"\n    TOKENIZER = tokenizers.BertWordPieceTokenizer(\n        f\"{BERT_PATH}/vocab.txt\", \n        lowercase=True\n    ) \n    Rb_TOKENIZER=tokenizers.ByteLevelBPETokenizer( \n    f\"{ROBERTA_PATH}/vocab.json\", \n    f\"{ROBERTA_PATH}/merges.txt\", \n    lowercase=True,\n    add_prefix_space=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_bert_data(tweet, selected_text, sentiment, tokenizer, max_len):\n    len_st = len(selected_text)\n    idx0 = None\n    idx1 = None\n    \n    # Getting the start and end indices of the selected_text in tweet \n    for ind in (i for i, e in enumerate(tweet) if e == selected_text[0]):\n        if tweet[ind: ind+len_st] == selected_text:\n            idx0 = ind\n            idx1 = ind + len_st - 1\n            break\n    \n    # Creating a list of 0's same length as tweet \n    # then filling all the indices where tweet == selected_text with 1's \n    # ex - char_targets before = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n    char_targets = [0] * len(tweet)\n    if idx0 != None and idx1 != None:\n        for ct in range(idx0, idx1 + 1):\n            char_targets[ct] = 1\n    # char_targets after = [0,0,0,0,0,1,1,1,1,1,1,0,0,0,0]  at character level not word level\n    \n    # tokenizing each tweet\n    tok_tweet = tokenizer.encode(tweet)\n    input_ids_orig = tok_tweet.ids[1:-1]  #not considering cls and sep token\n    tweet_offsets = tok_tweet.offsets[1:-1] #shape[(1,5)] [(token's starting index,endingindex)]\n\n    # we recieved a list of token offets\n    # Now we want a list of indices of the words where tweet == selected_text   \n    target_idx = []\n    for j, (offset1, offset2) in enumerate(tweet_offsets):\n        if sum(char_targets[offset1: offset2]) > 0:\n            target_idx.append(j)\n    \n    # getting the starting and ending indices where tweet == selected_text \n    targets_start = target_idx[0]\n    targets_end = target_idx[-1]\n\n    sentiment_id = {\n        'positive': 3893,\n        'negative': 4997,\n        'neutral': 8699\n    }\n    \n    # adding 3 more tokens at the start\n    input_ids = [101] + [sentiment_id[sentiment]] + [102] + input_ids_orig + [102]\n    token_type_ids = [0, 0, 0] + [1] * (len(input_ids_orig) + 1)\n    mask = [1] * len(token_type_ids)\n    tweet_offsets = [(0, 0)] * 3 + tweet_offsets + [(0, 0)]\n    targets_start += 3 # adding 3 more indices to the target_start\n    targets_end += 3   # adding 3 more indices to the target_end\n\n    # if max length>length of input_id then add pading to input_ids,mask,token_type_ids,tweet_offset\n    padding_length = max_len - len(input_ids)\n    if padding_length > 0:\n        input_ids = input_ids + ([0] * padding_length)\n        mask = mask + ([0] * padding_length)\n        token_type_ids = token_type_ids + ([0] * padding_length)\n        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n    \n    # So as a whole we will be returning input_ids,mask,toke_type_ids,targets_start,targets_end\n    #original tweet ,original selected text , sentiment , tweet offsets\n    return {\n        'ids': input_ids, # input_ids=[101]+[sentiment_id[sentiment]]+[102]+input_ids_orig+[102]\n        'mask': mask, # [1] * len(token_type_ids)\n        'token_type_ids': token_type_ids, # [0, 0, 0] + [1] * (len(input_ids_orig) + 1)\n        'offsets': tweet_offsets, # [(0, 0)] * 3 + tweet_offsets + [(0, 0)]\n        'targets_start': targets_start, # targets_start = target_idx[0] + 3\n        'targets_end': targets_end, # targets_end = target_idx[-1] + 3\n        'orig_tweet': tweet, \n        'orig_selected': selected_text,\n        'sentiment': sentiment}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BertDataset:\n    def __init__(self, tweet, sentiment, selected_text):\n        self.tweet = tweet\n        self.sentiment = sentiment\n        self.selected_text = selected_text\n        self.tokenizer = config.TOKENIZER\n        self.max_len = config.MAX_LEN\n    \n    def __len__(self):\n        return len(self.tweet)\n\n    def __getitem__(self, item):\n        data = process_bert_data(\n            self.tweet[item], \n            self.selected_text[item], \n            self.sentiment[item],\n            self.tokenizer,\n            self.max_len\n        )\n       \n    # Return the processed data where the lists are converted to `torch.tensor`s\n        return {\n            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n            'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long),\n            'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.long),\n            'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.long),\n            'orig_tweet': data[\"orig_tweet\"],\n            'orig_selected': data[\"orig_selected\"],\n            'sentiment': data[\"sentiment\"]\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BertModel(transformers.BertPreTrainedModel):\n    \"\"\"\n    Model class that combines a pretrained bert model with a linear later\n    \"\"\"\n    def __init__(self, conf):\n        super(BertModel, self).__init__(conf)\n        # Load the pretrained BERT model\n        self.bert = transformers.BertModel.from_pretrained(config.BERT_PATH, config=conf)\n        \n        # Set 10% dropout to be applied to the BERT backbone's output\n        self.drop_out = nn.Dropout(0.1)\n        \n        # 768 is the dimensionality of bert-base's hidden representations\n        # Multiplied by 2 since the forward pass concatenates last two hidden representation layers\n        # The output will have two dimensions (\"start_logits\", and \"end_logits\")\n        self.l0 = nn.Linear(768, 2)\n        \n        torch.nn.init.normal_(self.l0.weight, std=0.02)\n        torch.nn.init.normal_(self.l0.bias,0)\n    \n    def forward(self, ids, mask, token_type_ids):\n        # seqeunce_ouput , pooled_output , outputs_hidden_state  \n        outputs = self.bert(\n            ids,\n            attention_mask=mask,\n            token_type_ids=token_type_ids\n        )\n        #batch_size(bs) x Sequence_Length(SL) x Embedding(768X2) [(batch_size,num_tokens,768X2)]\n        \n        # Concatenate the last two hidden states\n        # This is done since experiments have shown that just getting the last layer\n        # gives out vectors that may be too taylored to the orig BERT training objectives(MLM + NSP)\n        \n        out = torch.stack((outputs.hidden_states[-1], outputs.hidden_states[-2], \n                         outputs.hidden_states[-3], outputs.hidden_states[-4])) \n        out = torch.mean(out, 0)\n        # bs x SL x (768)\n        \n        # Apply 10% dropout to the last 2 hidden states\n        out = self.drop_out(out)  # bs x SL x (768)\n        \n        # The \"dropped out\" hidden vectors are now fed into the linear layer to output two scores\n        logits = self.l0(out) # bs x SL x 2\n\n        # Splits the tensor into start_logits and end_logits\n        # (bs x SL x 2) -> (bs x SL x 1), (bs x SL x 1)\n        start_logits, end_logits = logits.split(1, dim=-1)\n\n        start_logits = start_logits.squeeze(-1) # (bs x SL)\n        end_logits = end_logits.squeeze(-1) # (bs x SL)\n\n        return start_logits, end_logits","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_fn(start_logits, end_logits, start_positions, end_positions):\n    \"\"\"\n    Return the sum of the cross entropy losses for both the start and end logits\n    \"\"\"\n    loss_fct = nn.CrossEntropyLoss()\n    start_loss = loss_fct(start_logits, start_positions)\n    end_loss = loss_fct(end_logits, end_positions)\n    total_loss = (start_loss + end_loss)\n    return total_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_jaccard_score(\n    original_tweet, \n    target_string, \n    sentiment_val, \n    idx_start, \n    idx_end, \n    offsets,\n    verbose=False):\n    \n    \"\"\"\n    Calculate the jaccard score from the predicted span and the actual span for a batch of tweets\n    \"\"\"\n    \n    # A span's start index has to be less than or equal to the end index\n    # If this doesn't hold, the end index is set to equal the start index (span is a single token)\n    if idx_end < idx_start:\n        idx_end = idx_start\n    \n    filtered_output  = \"\"\n    for ix in range(idx_start, idx_end + 1):\n        filtered_output += original_tweet[offsets[ix][0]: offsets[ix][1]]\n        # If the token is not last token in the tweet, and ending offset of current token is less\n         # than the beginning offset of the following token, add a space.\n        # Basically, add a space when the next token (word piece) corresponds to a new word\n        if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n            filtered_output += \" \"\n   \n    # Set the predicted output as the original tweet when the tweet's sentiment is \"neutral\", \n    # or the tweet's len is less than or equal to 4\n    if sentiment_val == \"neutral\" or len(original_tweet) <= 4: \n        filtered_output = original_tweet\n    \n    # Calculate the jaccard score between the predicted span, and the actual span\n    # The IOU (intersection over union) approach is detailed in the utils module's `jaccard` function:\n    # https://www.kaggle.com/abhishek/utils\n    jac = utils.jaccard(target_string.strip(), filtered_output.strip())\n    return jac, filtered_output\n\ndef train_fn(data_loader, model, optimizer, device, scheduler=None):\n    \"\"\"\n    Trains the bert model on the twitter data\n    \"\"\"\n    # Set model to training mode (dropout + sampled batch norm is activated)\n    model.train()\n    losses = utils.AverageMeter()\n    jaccards = utils.AverageMeter()\n\n    # Set tqdm to add loading screen and set the length\n    tk0 = tqdm(data_loader, total=len(data_loader))\n    \n    for bi, d in enumerate(tk0):\n\n        ids = d[\"ids\"]\n        token_type_ids = d[\"token_type_ids\"]\n        mask = d[\"mask\"]\n        offsets = d[\"offsets\"]\n        targets_start = d[\"targets_start\"]\n        targets_end = d[\"targets_end\"]\n        sentiment = d[\"sentiment\"]\n        orig_selected = d[\"orig_selected\"]\n        orig_tweet = d[\"orig_tweet\"]\n        \n        # Move ids, masks, and targets to gpu while setting as torch.long\n        ids = ids.to(device, dtype=torch.long)\n        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n        mask = mask.to(device, dtype=torch.long)\n        targets_start = targets_start.to(device, dtype=torch.long)\n        targets_end = targets_end.to(device, dtype=torch.long)\n\n        # Reset gradients\n        model.zero_grad()\n        \n        # Use ids, masks, and token types as input to the model\n        # Predict logits for each of the input tokens for each batch\n        outputs_start, outputs_end = model(\n            ids=ids,\n            mask=mask,\n            token_type_ids=token_type_ids\n        )# (bs x SL), (bs x SL)\n        \n        # Calculate batch loss based on CrossEntropy\n        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n        # Calculate gradients based on loss\n        loss.backward()\n        # Adjust weights based on calculated gradients\n        optimizer.step()\n        # Update scheduler\n        if scheduler is not None: scheduler.step()\n        \n        # Apply softmax to the start and end logits\n        # This squeezes each of the logits in a sequence to a value between 0 and 1, \n        # while ensuring that they sum to 1\n        # This is similar to the characteristics of \"probabilities\"\n        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n        \n        # Calculate the jaccard score based on the predictions for this batch\n        jaccard_scores = []\n        for px, tweet in enumerate(orig_tweet):\n            selected_tweet = orig_selected[px] \n            tweet_sentiment = sentiment[px]\n            jaccard_score, _ = calculate_jaccard_score(\n                original_tweet=tweet, # Full text of the px'th tweet in the batch\n                target_string=selected_tweet,# Span containing the specified sentiment for tweet\n                sentiment_val=tweet_sentiment, # Sentiment of the px'th tweet in the batch\n                idx_start=np.argmax(outputs_start[px, :]), # Predicted start index for px'th tweet \n                idx_end=np.argmax(outputs_end[px, :]),# Predicted end index for px'th tweet in batch\n                offsets=offsets[px] # Offsets for each of the tokens for px'th tweet in the batch\n            )\n            jaccard_scores.append(jaccard_score)\n        # Update the jaccard score and loss\n        # For details, refer to `AverageMeter` in https://www.kaggle.com/abhishek/utils\n        jaccards.update(np.mean(jaccard_scores), ids.size(0))\n        losses.update(loss.item(), ids.size(0))\n        # Print the average loss and jaccard score at the end of each batch\n        tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_fn(data_loader, model, device):\n    \"\"\"\n    Evaluation function to predict on the test set\n    \"\"\"\n    # Set model to evaluation mode\n    # I.e., turn off dropout and set batchnorm to use overall mean and variance (from training), \n    #rather than batch level mean and variance\n    model.eval()\n    losses = utils.AverageMeter()\n    jaccards = utils.AverageMeter()\n    \n    # Turns off gradient calculations \n#(https://datascience.stackexchange.com/questions/32651/what-is-the-use-of-torch-no-grad-in-pytorch)\n    with torch.no_grad():\n        tk0 = tqdm(data_loader, total=len(data_loader))\n        # Make predictions and calculate loss / jaccard score for each batch\n        for bi, d in enumerate(tk0):\n            ids = d[\"ids\"]\n            token_type_ids = d[\"token_type_ids\"]\n            mask = d[\"mask\"]\n            sentiment = d[\"sentiment\"]\n            orig_selected = d[\"orig_selected\"]\n            orig_tweet = d[\"orig_tweet\"]\n            targets_start = d[\"targets_start\"]\n            targets_end = d[\"targets_end\"]\n            offsets = d[\"offsets\"].numpy()\n            # Move ids, masks, and targets to gpu while setting as torch.long\n            ids = ids.to(device, dtype=torch.long)\n            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n            mask = mask.to(device, dtype=torch.long)\n            targets_start = targets_start.to(device, dtype=torch.long)\n            targets_end = targets_end.to(device, dtype=torch.long)\n\n            # Predict logits for start and end indexes\n            outputs_start, outputs_end = model(\n                ids=ids,\n                mask=mask,\n                token_type_ids= token_type_ids\n            )\n            \n            # Calculate loss for the batch\n            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n            # Apply softmax to the predicted logits for the start and end indexes\n            # This converts the \"logits\" to \"probability-like\" scores\n            outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n            outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n            # Calculate jaccard scores for each tweet in the batch\n            jaccard_scores = []\n            for px, tweet in enumerate(orig_tweet):\n                selected_tweet = orig_selected[px]\n                tweet_sentiment = sentiment[px]\n                jaccard_score, _ = calculate_jaccard_score(\n                    original_tweet=tweet,\n                    target_string=selected_tweet,\n                    sentiment_val=tweet_sentiment,\n                    idx_start=np.argmax(outputs_start[px, :]),\n                    idx_end=np.argmax(outputs_end[px, :]),\n                    offsets=offsets[px]\n                )\n                jaccard_scores.append(jaccard_score)\n                # Update running jaccard score and loss\n            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n            losses.update(loss.item(), ids.size(0))\n            # Print the running average loss and jaccard score\n            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n    \n    print(f\"Jaccard = {jaccards.avg}\")\n    return jaccards.avg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_bert():\n    avg_jaccard=0\n    total_jaccard=0\n    for fold in range(config.FOLDS):\n        # Read training csv\n        dfx = pd.read_csv(config.TRAINING_FILE)\n\n        # Set train validation set split\n        df_train = dfx[dfx.kfold != fold].reset_index(drop=True)\n        df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n    \n        # Instantiate BertDataset with training data\n        train_dataset = BertDataset(\n        tweet=df_train.text.values,\n        sentiment=df_train.sentiment.values,\n        selected_text=df_train.selected_text.values\n        )\n\n        # Instantiate DataLoader with `train_dataset`\n        # This is a generator that yields the dataset in batches\n        train_data_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=config.TRAIN_BATCH_SIZE,\n        num_workers=4\n        )\n \n        # Instantiate BertDataset with validation data\n        valid_dataset = BertDataset(\n        tweet=df_valid.text.values,\n        sentiment=df_valid.sentiment.values,\n        selected_text=df_valid.selected_text.values\n        )\n\n        # Instantiate DataLoader with `valid_dataset`\n        valid_data_loader = torch.utils.data.DataLoader(\n        valid_dataset,\n        batch_size=config.VALID_BATCH_SIZE,\n        num_workers=2\n        )\n\n       # Set device as `cuda` (GPU)\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n       # load pretrained Bert model \n        bert_config = transformers.BertConfig.from_pretrained(config.BERT_PATH)\n       # Output hidden states\n       # This is important to set since we want to concatenate the hidden states from the last 2 BERT layers\n        bert_config.output_hidden_states = True\n       # Instantiate our model with `model_config`\n        bert_model = BertModel(conf=bert_config)\n       # Move the model to the GPU if cuda available else cpu\n        bert_model.to(device)\n\n       # Calculate the number of training steps\n        num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n       # Get the list of named parameters\n        param_optimizer = list(bert_model.named_parameters())\n       # Specify parameters where weight decay shouldn't be applied\n        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n       # Define two sets of parameters: those with weight decay, and those without\n        optimizer_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n       ]\n    \n       # Instantiate AdamW optimizer with our two sets of parameters, and a learning rate of 3e-5\n        optimizer = AdamW(optimizer_parameters, lr=3e-5)\n       # Create a scheduler to set the learning rate at each training step\n       # \"Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period.\" \n       #(https://pytorch.org/docs/stable/optim.html)\n       # Since num_warmup_steps = 0, the learning rate starts at 3e-5, and then linearly decreases at each training step\n        scheduler = get_linear_schedule_with_warmup(\n        optimizer, \n        num_warmup_steps=0, \n        num_training_steps=num_train_steps\n       )\n\n       # Apply early stopping with patience of 2\n       # This means to stop training new epochs when 2 rounds have passed without any improvement\n        es = utils.EarlyStopping(patience=2, mode=\"max\")\n        print(f\"Training is Starting for fold={fold}\")\n    \n        for epoch in range(config.EPOCHS):\n            train_fn(train_data_loader, bert_model, optimizer, device, scheduler=scheduler)\n            jaccard = eval_fn(valid_data_loader, bert_model, device)\n            print(f\"Jaccard Score = {jaccard}\")\n            total_jaccard += jaccard \n            #saving the model to model_path while taking early stopping into consideration as well \n            es(jaccard, bert_model, model_path=f\"model_bert_{fold}.bin\")\n            if es.early_stop:\n                print(\"Early stopping\")\n                break\n    \n    avg_jaccard = (total_jaccard)/(config.FOLDS*config.EPOCHS)   \n    print(f'Bert Model Avg jaccard score over all folds and epochs is {avg_jaccard}')\n    return avg_jaccard","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import utils","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_score=run_bert()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_score=[]\n# Instantiate BertDataset with the test data\ntest_dataset = BertDataset(\n        tweet=df_test.text.values,\n        sentiment=df_test.sentiment.values,\n        selected_text=df_test.selected_text.values\n)\n\n# Instantiate DataLoader with `test_dataset`\ndata_loader = torch.utils.data.DataLoader(\n    test_dataset,\n    shuffle=False,\n    batch_size=config.VALID_BATCH_SIZE,\n    num_workers=1\n)\n# Turn of gradient calculations\nwith torch.no_grad():\n    tk0 = tqdm(data_loader, total=len(data_loader))\n    # Predict the span containing the sentiment for each batch\n    for bi, d in enumerate(tk0):\n        ids = d[\"ids\"]\n        token_type_ids = d[\"token_type_ids\"]\n        mask = d[\"mask\"]\n        sentiment = d[\"sentiment\"]\n        orig_selected = d[\"orig_selected\"]\n        orig_tweet = d[\"orig_tweet\"]\n        targets_start = d[\"targets_start\"]\n        targets_end = d[\"targets_end\"]\n        offsets = d[\"offsets\"].numpy()\n\n        ids = ids.to(device, dtype=torch.long)\n        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n        mask = mask.to(device, dtype=torch.long)\n        targets_start = targets_start.to(device, dtype=torch.long)\n        targets_end = targets_end.to(device, dtype=torch.long)\n         # Predict start and end logits for each of the five models\n        outputs_start1, outputs_end1 = bert1(\n            ids=ids,\n            mask=mask,\n            token_type_ids=token_type_ids\n        )\n        \n        outputs_start2, outputs_end2 = bert2(\n            ids=ids,\n            mask=mask,\n            token_type_ids=token_type_ids\n        )\n        \n        outputs_start3, outputs_end3 = bert3(\n            ids=ids,\n            mask=mask,\n            token_type_ids=token_type_ids\n        )\n        \n        outputs_start4, outputs_end4 = bert4(\n            ids=ids,\n            mask=mask,\n            token_type_ids=token_type_ids\n        )\n        outputs_start5, outputs_end5 = bert5(\n            ids=ids,\n            mask=mask,\n            token_type_ids=token_type_ids\n        )\n        \n        # Get the average start and end logits across the five models and use these as predictions\n        # This is a form of \"ensembling\"\n        outputs_start = (\n            outputs_start1 \n            + outputs_start2 \n            + outputs_start3 \n            + outputs_start4 \n            + outputs_start5\n        ) / 5\n        outputs_end = (\n            outputs_end1 \n            + outputs_end2 \n            + outputs_end3 \n            + outputs_end4 \n            + outputs_end5\n        ) / 5\n         # Apply softmax to the predicted start and end logits\n        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n\n        # Convert the start and end scores to actual predicted spans (in string form)\n        for px, tweet in enumerate(orig_tweet):\n            selected_tweet = orig_selected[px]\n            tweet_sentiment = sentiment[px]\n            _, output_sentence = calculate_jaccard_score(\n                original_tweet=tweet,\n                target_string=selected_tweet,\n                sentiment_val=tweet_sentiment,\n                idx_start=np.argmax(outputs_start[px, :]),\n                idx_end=np.argmax(outputs_end[px, :]),\n                offsets=offsets[px]\n            )\n            final_output.append(output_sentence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.loc[:, 'selected_text'] = final_output\ndf_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv(\"../input/tweet-sentiment-extraction/sample_submission.csv\")\nsample.loc[:, 'selected_text'] = final_output\nsample.to_csv(\"submission_bert.csv\", index=False)\nsample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}